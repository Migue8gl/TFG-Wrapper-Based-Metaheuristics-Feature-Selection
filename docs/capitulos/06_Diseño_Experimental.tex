\chapter{Diseño experimental}
En este capítulo se describirá el proceso de experimentación llevado a cabo, los conjuntos de datos usados para los distintos experimentos y los parámetros usados en cada uno de los algoritmos.\\[6pt]

\begin{table}[htp]
    \centering
    \begin{tabular}{ l c c c c }
        \hline
        \textbf{Dataset} & \textbf{Instancias} & \textbf{Características} & \textbf{Clases} & \textbf{Área} \\ \hline
        sonar            & 207                 & 60                       & 2               & Biología      \\
        spambase-460     & 459                 & 54                       & 2               & Informática   \\
        spectf-heart     & 348                 & 44                       & 2               & Medicina      \\
        waveform5000     & 5000                & 40                       & 3               & Física        \\
        ionosphere       & 350                 & 34                       & 2               & Meteorología  \\
        dermatology      & 366                 & 34                       & 6               & Medicina      \\
        wdbc             & 568                 & 29                       & 2               & Medicina      \\
        parkinsons       & 200                 & 22                       & 2               & Medicina      \\
        zoo              & 101                 & 18                       & 7               & Biología      \\
        wine             & 182                 & 13                       & 3               & Alimentación  \\
        breast-cancer    & 286                 & 9                        & 2               & Medicina      \\
        diabetes         & 768                 & 8                        & 2               & Medicina      \\
        yeast            & 1483                & 8                        & 10              & Biología      \\
        ecoli            & 336                 & 7                        & 8               & Biología      \\
        iris             & 149                 & 4                        & 3               & Biología      \\ \hline
    \end{tabular}
    \caption{Información de los conjuntos de datos ordenada por número de características}
    \label{tab:datasets_info}
\end{table}

Se han seleccionado los conjuntos de datos descritos en la tabla \ref{tab:datasets_info} por los siguientes motivos:
\begin{itemize}
    \item \textbf{Variedad de áreas:} Se ha buscado representar una amplia gama de áreas, como Medicina, Biología, Alimentación, Meteorología, Física e Informática. Esto asegura que los problemas abordados sean variados y abarquen diferentes dominios de aplicación.
    \item \textbf{Diversidad de problemas:} Los conjuntos de datos elegidos cubren una variedad de problemas, desde diagnósticos médicos y clasificación de especies hasta predicciones en meteorología y detección de spam. Esta diversidad permite evaluar el rendimiento de los algoritmos en múltiples contextos.
    \item \textbf{Número de características:} Algunos conjuntos de datos, como \textit{spectf-heart} y \textit{spambase-460}, tienen un gran número de características, lo que es particularmente útil para evaluar la eficacia de las técnicas de selección de características. Esta variedad en el número de características permite probar la robustez de los algoritmos en situaciones de alta dimensionalidad. La inclusión de otros como \textit{iris} con tan pocas características hacen de conjunto de datos de referencia, todos los algoritmos deberían optimizar este \textit{dataset}.
    \item \textbf{Popularidad y uso en investigaciones:} Los conjuntos de datos seleccionados son populares y ampliamente utilizados en estudios y artículos de referencia~\cite{zhang_return-cost-based_2017, mafarja_binary_2019, emary_binary_2016, mafarja_whale_2018}. Esto facilita la comparación de resultados con otros trabajos y asegura que los datos son reconocidos y aceptados en la comunidad científica.
    \item \textbf{Variedad en el número de instancias y clases:} La selección incluye conjuntos de datos con diferentes números de instancias y clases. Esta variedad es crucial para probar la escalabilidad y versatilidad de los algoritmos.
    \item \textbf{Relevancia práctica:} Muchos de estos conjuntos de datos, como \textit{diabetes} y \textit{breast-cancer}, tienen una alta relevancia práctica en sus respectivas áreas, lo que subraya la importancia de encontrar soluciones eficientes y precisas para problemas del mundo real.
\end{itemize}
Los datos han sido normalizados entres $0$ y $1$ siguiendo la función de normalización \textit{MinMaxScaler} de \textit{scikit-learn}~\cite{scikit-learn}. Los conjuntos de datos se han dividido en $20\%$ test, $20\%$ validación y $60\%$ entrenamiento.
Se han llevado a cabo $10$ ejecuciones sobre cada algoritmo en cada conjunto de datos, tanto en su versión original como en su versión binaria. Estas ejecuciones se han procesado de forma paralela en el servidor de \textit{Hércules}~\cite{citicugr}. Este servidor está constituido por $19$ nodos de cómputo, donde cada nodo contiene dos procesadores capaces de ejecutar $24$ hebras cada uno. Este servidor utiliza el sistema \textit{SLURM} para la gestión del trabajo entre nodos. De esta forma se paraleliza el trabajo de cada experimento con cada algoritmo.\\[6pt]
Se han recabado datos de todas las ejecuciones para poder comparar los resultados. En forma de gráficos se ha representado la curva de convergencia de cada algoritmo además de una curva de decremento de las características de cada conjunto de datos. Ambos gráficos son muy interesantes a la hora de comparar algoritmos para un mismo conjunto de datos.\\[6pt]
Además se han recabado los siguientes datos en ficheros de texto para su posterior análisis:
\begin{itemize}
    \item \textbf{classifier}: Clasificador usado (kNN o SVC).
    \item \textbf{dataset}: El conjunto de datos utilizado para el proceso de selección de características.
    \item \textbf{optimizer}: Algoritmo metaheurístico usado como optimizador.
    \item \textbf{all\_fitness}: Lista que contiene los valores \textit{fitness} de todas las soluciones generadas durante la optimización.
    \item \textbf{best}: Mejor valor encontrado durante la optimización.
    \item \textbf{avg}: Promedio de los valores de \textit{fitness} de todas las soluciones generadas durante la optimización.
    \item \textbf{std\_dev}: Desviación estándar de los valores de \textit{fitness} de todas las soluciones generadas durante la optimización. Indica qué tan dispersos están los valores alrededor del promedio.
    \item \textbf{acc}: Precisión (accuracy) del modelo de clasificación, es decir, la proporción de instancias correctamente clasificadas sobre el total de instancias.
    \item \textbf{n\_features}: Número de características seleccionadas.
    \item \textbf{selected\_rate}: Tasa de selección de características, que representa la proporción de características seleccionadas respecto al total de características disponibles.
    \item \textbf{execution\_time}: Tiempo de ejecución del algoritmo optimizatorio.
\end{itemize}
Para la función de \textit{fitness} se ha usado:
\begin{equation}
    fitness = acc\cdot\alpha + red\cdot(1-\alpha)
    \label{eq:fitness}
\end{equation}
Donde \textit{acc} quiere decir precisión y \textit{red} el porcentaje de características reducidas. Otra forma de proponer la ecuación es reduciendo el error de precisión y las características seleccionadas, es exactamente lo mismo. La variable $\alpha$ actúa como medio de ponderación y ha sido fijado en $\alpha=0.9$, dando un $90\%$ de prioridad a la precisión.
Se procede a mostrar los parámetros fijados para cada algoritmo (como referencia se han seguido los parámetros de los artículos originales y binarios ya citados para cada algoritmo).\\[6pt]
Los parámetros fijados en cada uno de los algoritmos de optimización metaheurísticos han sido elegidos por las recomendaciones dadas en los artículos de referencia de los que se sacan, más concretamente los artículos que presentan la versión binaria. Estos son citados en la descripción de cada tabla.

\begin{table}[htp]
    \centering
    \begin{tabular}{c|c}
        \hline
        \textbf{Algoritmo}                 & \textbf{Parámetros}                                                                                                                          \\
        \hline
        GOA~\cite{mafarja_binary_2019}     & \begin{tabular}[c]{@{}c@{}}$c_{min}$: 0.00001\ $c_{max}$: 1\ F: 0.5\ L: 1.5\end{tabular}         \\
        WOA~\cite{Li2019AnAW}              & Parámetro espiral: 1                                                                                                                         \\
        ABCO~\cite{karaboga_idea_nodate}   & \begin{tabular}[c]{@{}c@{}}Abeja empleada: 3\ Abeja vigilante: 3\ Límite: 3\end{tabular}                                                     \\
        BA~\cite{mirjalili_binary_2014}    & \begin{tabular}[c]{@{}c@{}}$\alpha$: 0.9\ $\gamma$: 0.9\ $f_{min}$: 0\ $f_{max}$: 2\end{tabular} \\
        PSO~\cite{mirjalili_s-shaped_2013} & \begin{tabular}[c]{@{}c@{}}w: 0.9\ $c_1$: 2\ $c_2$: 2\end{tabular}                                                                           \\
        FA~\cite{zhang2016optimal}         & \begin{tabular}[c]{@{}c@{}}$\alpha_0$: 0.5\ $\beta_0$: 0.2\ $\gamma_0$: 1\end{tabular}                                                       \\
        GA\cite{10.5555/522098}            & \begin{tabular}[c]{@{}c@{}}Ratio de cruce: 1\ Ratio de mutación: 0.05\ Elite: 2\ $\eta$: 1\ $\alpha$: $\sqrt{0.3}$\end{tabular}  \\
        ACO~\cite{kashef_advanced_2015}    & \begin{tabular}[c]{@{}c@{}}$\alpha$: 1\ Q: 1\ Feromona inicial: 0.1\ Ratio de evaporación: 0.049\end{tabular}                                \\
        CS~\cite{rodrigues_bcs_2013}       & \begin{tabular}[c]{@{}c@{}}Ratio de descubrimiento: 0.25\ $\alpha$: 1\ $\lambda$: 1.5\end{tabular}                                           \\
        DE~\cite{storn_differential_1997}  & \begin{tabular}[c]{@{}c@{}}F: 0.5\ Cr: 0.1\end{tabular}                                                                                      \\
        \hline
    \end{tabular}
    \caption{Parámetros de diferentes algoritmos de optimización}
\end{table}

En la mayoría de algoritmos, se han escogido los parámetros recomendados por los autores. Dada la cantidad de variantes y cantidad de valores de parámetros propuestos en \textbf{GA}, estos han sido escogidos de manera empírica y basándose en recomendaciones del tutor del proyecto. En \textbf{WOA}, en el paper original~\cite{mirjalili_whale_2016} y en el de la versión binaria~\cite{mafarja_whale_2018}, no se da un valor. El valor por defecto ha sido sacado de la implementación de~\cite{Li2019AnAW}. Los algoritmos de \textbf{DA} y \textbf{GWO} no tienen parámetros configurables. Todos los algoritmos son inicializados con el mismo número de individuos, de forma que las comparaciones entre ellos sean equivalentes.\\[6pt]
Cada destacar que el algoritmo \textbf{ACO} no se ha añadido al grupo de experimentación de los algoritmos continuos, debido a la naturaleza de su diseño, pues se considera que las versiones existentes en codificación real perturban demasiado el diseño de este, además de que por su propia inspiración no tendría sentido su modificación.\\[6pt]
Por último, cabe mencionar que se ha introducido un límite de corte en la selección de características. De este método se benefician sobre todo los algoritmos continuos, debido a que estos ajustan los pesos en el rango de valores de $[0,1]$, pero no reducen completamente como los binarios. De esta forma, toda característica que tenga un peso asociado menor a $0.05$ se considera suficientemente irrelevante como para descartarla.\\[6pt]

Para evaluar el rendimiento de los algoritmos, se plantean las siguientes hipótesis:

\textbf{Hipótesis nula (\(H_0\))}:
\begin{equation}
    H_0: \text{Rendimiento}_{Alg_1} \leq \text{Rendimiento}_{Alg_2}
\end{equation}

\textbf{Hipótesis alternativa (\(H_1\))}:
\begin{equation}
    H_1: \text{Rendimiento}_{Alg_1} > \text{Rendimiento}_{Alg_2}
\end{equation}

Se va a usar el test de \textit{Wilcoxon}~\cite{Rey2011} junto a un \textit{post hoc} de \textit{Holms}~\cite{holm1979simple}. El test de \textit{Wilcoxon} es una prueba no paramétrica que se utiliza para comparar dos conjuntos de datos emparejados. Este test es útil cuando se quiere determinar si existe una diferencia significativa entre dos condiciones (por ejemplo, el rendimiento de dos algoritmos) sin asumir que los datos siguen una distribución normal. El procedimiento \textit{post hoc} de \textit{Holm} es una técnica utilizada para controlar la tasa de error tipo en múltiples comparaciones. En estudios donde se realizan múltiples pruebas estadísticas (como es el caso), la probabilidad de obtener resultados falsos positivos aumenta y por ello se necesita de este corrector a la hora de realizar afirmaciones sobre los tests.