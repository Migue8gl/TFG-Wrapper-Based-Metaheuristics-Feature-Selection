\chapter*{}
%\thispagestyle{empty}
%\cleardoublepage

%\thispagestyle{empty}

\cleardoublepage
\thispagestyle{empty}

\begin{center}
       {\large\bfseries Estudio y Análisis de Metaheurísticas modernas para el problema de Selección de Características}\\
\end{center}
\begin{center}
       MIGUEL GARCÍA LÓPEZ\\
\end{center}

%\vspace{0.7cm}
\noindent{\textbf{Palabras clave}: Metaheurística, selección de características, binario, optimización, población, fitness, aprendizaje automático}\\

\vspace{0.7cm}
\noindent{\textbf{Resumen}}\\

En el ámbito del \textit{Machine Learning}, algunos algoritmos, como KNN o SVM, muestran excelentes resultados, pero a menudo requieren un procesamiento previo para identificar las características más relevantes. Esto se debe a que, ya sea por la amplitud y complejidad del problema, por falta de conocimiento o contexto al recolectar los datos, es posible aglomerar información innecesaria, dando lugar a conjuntos de datos inmensos. Incluso los algoritmos que internamente realizan esta identificación pueden beneficiarse de un procesamiento adicional. Este preprocesamiento, conocido como selección de características (\textit{feature selection}), se considera un problema complejo de optimización combinatoria.\\[6pt]

Existen varios métodos comunes para la selección de características: filtrado, envoltura (Wrapper), métodos basados en árboles, Análisis de Componentes Principales (PCA) y selección L1 (Lasso Regression).\\[6pt]

Estos métodos pueden utilizarse individualmente o en combinación para mejorar la selección de características y el rendimiento de los modelos de \textit{Machine Learning}. En este documento se hablarán de métodos metaheurísticos para la resolución de este problema.\\[6pt]

Las metaheurísticas son algoritmos diseñados para resolver problemas de optimización complejos cuando los recursos son limitados. Aunque inicialmente se desarrollaron para abordar principalmente problemas combinatorios, en la actualidad se están proponiendo y aplicando cada vez más en problemas que implican variables continuas o reales. En respuesta a la creciente demanda en el campo de la selección de características, se han adaptado versiones especializadas de estas metaheurísticas para abordar este tipo de problemas combinatorios. Sin embargo, a pesar del número creciente de propuestas en este campo, las comparaciones objetivas entre ellas son limitadas. Aunque existen revisiones bibliográficas, muchas de ellas carecen de comparaciones adecuadas debido a la importancia y actualidad del problema de selección de características. Por lo tanto, hay una necesidad de estudios que proporcionen una evaluación comparativa más rigurosa y exhaustiva de las diferentes propuestas en este ámbito.\\[6pt]

Existe por tanto una necesidad de estudios que proporcionen una evaluación comparativa más rigurosa y exhaustiva de las diferentes propuestas en este ámbito, planteando un doble estudio que use tanto adaptaciones binarias como reales con algoritmos modernos.\\[6pt]

En este trabajo de carácter científico, se llevará a cabo una revisión bibliográfica de diversas metaheurísticas recientes para abordar el problema de selección de características. Se estudiarán e implementarán aquellas consideradas más prometedoras, con el objetivo de construir un repertorio amplio y variado de propuestas. Posteriormente, se realizará un estudio comparativo exhaustivo utilizando diversos algoritmos de machine learning y conjuntos de datos representativos. Finalmente, se llevará a cabo un análisis crítico utilizando diversas métricas y valoraciones, como la tasa de acierto y el tiempo de ejecución, entre otras.
\cleardoublepage


\thispagestyle{empty}


\begin{center}
       {\large\bfseries Study and Analysis of Modern Metaheuristics for the Feature Selection Problem}\\
\end{center}
\begin{center}
       MIGUEL GARCÍA LÓPEZ\\
\end{center}

%\vspace{0.7cm}
\noindent{\textbf{Keywords}: Metaheuristic, feature selection, binary, optimization, population, fitness, machine learning}\\

\vspace{0.7cm}
\noindent{\textbf{Abstract}}\\

In the field of Machine Learning, some algorithms, such as KNN or SVM, show excellent results, but often require preprocessing to identify the most relevant features. This is because, whether due to the broad and complex nature of the problem, lack of knowledge, or lack of context when collecting data, it is possible to aggregate unnecessary information, resulting in immense datasets. Even algorithms that internally perform this identification can benefit from additional processing. This preprocessing, known as feature selection, is considered a complex combinatorial optimization problem.

There are several common methods for feature selection: filtering, wrapping (Wrapper), tree-based methods, Principal Component Analysis (PCA), and L1 selection (Lasso Regression).\\[6pt]

These methods can be used individually or in combination to improve feature selection and the performance of \textit{Machine Learning} models. This document will discuss metaheuristic methods for solving this problem.\\[6pt]

Metaheuristics are algorithms designed to solve complex optimization problems when resources are limited. Initially developed mainly for combinatorial problems, they are increasingly proposed and applied to problems involving continuous or real variables. In response to the growing demand in feature selection, specialized versions of these metaheuristics have been adapted to tackle combinatorial problems. However, despite the increasing number of proposals in this field, objective comparisons between them are limited. Although there are literature reviews, many lack adequate comparisons due to the importance and timeliness of the feature selection problem. Therefore, there is a need for studies providing a more rigorous and exhaustive comparative evaluation of different proposals in this area.\\[6pt]

Therefore, there is a need for studies that provide a more rigorous and comprehensive comparative evaluation of the different proposals in this field, proposing a dual study that uses both binary and real adaptations with modern algorithms.\\[6pt]

In this scientific work, a literature review of various recent metaheuristics for feature selection will be conducted. The most promising ones will be studied and implemented to build a broad and varied repertoire of proposals. Subsequently, a comprehensive comparative study will be conducted using various machine learning algorithms and representative datasets. Finally, a critical analysis will be carried out using various metrics and assessments, such as accuracy rate and execution time, among others.\\[6pt]

\chapter*{}
\thispagestyle{empty}

\noindent\rule[-1ex]{\textwidth}{2pt}\\[4.5ex]

Yo, \textbf{Miguel García López}, alumno de la titulación Ingeniería Informática de la \textbf{Escuela Técnica Superior
       de Ingenierías Informática y de Telecomunicación de la Universidad de Granada}, con DNI 77159865E, autorizo la
ubicación de la siguiente copia de mi Trabajo Fin de Grado en la biblioteca del centro para que pueda ser
consultada por las personas que lo deseen.

\vspace{6cm}

\noindent Fdo: Miguel García López

\vspace{2cm}

\begin{flushright}
       Granada a 29 de Enero de 2024.
\end{flushright}


\chapter*{}
\thispagestyle{empty}

\noindent\rule[-1ex]{\textwidth}{2pt}\\[4.5ex]

D. \textbf{Daniel Molina Cabrera}, Profesor del Departamento Ciencias de la Computación e Inteligencia Artificial de la Universidad de Granada.

\vspace{0.5cm}
\textbf{Informan:}

\vspace{0.5cm}

Que el presente trabajo, titulado \textit{\textbf{Estudio y Análisis de Metaheurísticas modernas para el problema de Selección de Características}},
ha sido realizado bajo su supervisión por \textbf{Miguel García López}, y autorizamos la defensa de dicho trabajo ante el tribunal
que corresponda.

\vspace{0.5cm}

Y para que conste, expiden y firman el presente informe en Granada a 29 de Enero de 2024.

\vspace{1cm}

\textbf{El director:}

\vspace{5cm}

\noindent \textbf{Daniel Molina Cabrera}

\chapter*{Agradecimientos}
\thispagestyle{empty}

\vspace{1cm}


Me gustaría agradecer a mi tutor Daniel Molina Cabrera, profesor del Departamento de Ciencias de la Computación e Inteligencia Artificial de la Universidad de Granada, por su apoyo, instrucción y paciencia en la realización de este proyecto. Gracias a él y a la gran cantidad de tiempo que ha invertido en mí, este proyecto ha sido posible.\\[6pt] 
Segundo, quería agradecer a mi pareja, por su constante apoyo, por su atención y escucha en todo momento, incluso cuando no entendía mis explicaciones efusivas y confusas, por la motivación que me brindaba. Por todo ello le doy gracias.\\[6pt]
Gracias al lector, por dedicar su tiempo a la lectura de este documento, que con tanto cariño y empeño he redactado.\\[6pt]
Y por último gracias, a todas las personas que me rodean y me hacen la vida un poquito más bonita.\\[6pt]
